{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelado\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# WOE y IV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Para KS\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Configuración visual\n",
    "plt.style.use('ggplot')"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "En este notebook se realiza un análisis exploratorio de datos sobre el dataset de clientes de digital wallet, con el objetivo de comprender mejor los factores que afectan el Lifetime Value (LTV) de los clientes.\n",
    "\n",
    "## Preguntas de Interés\n",
    "\n",
    "1. **¿Cuáles son los factores más determinantes asociados a que un cliente tenga un LTV alto?**\n",
    "\n",
    "2. **¿Cómo varía el LTV según la frecuencia de uso de la app y el nivel de ingresos?**\n",
    "\n",
    "3. **¿Existen diferencias significativas en el LTV entre distintas ubicaciones geográficas?**\n",
    "\n",
    "A lo largo de este notebook se responderán estas preguntas utilizando análisis estadístico, visualizaciones y técnicas vistas en clase."
   ],
   "id": "c44d9e108c082ec4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv('../data/digital_wallet_ltv_dataset.csv')\n",
    "\n",
    "# Primer vistazo\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# Chequear valores nulos y duplicados\n",
    "print(df.isnull().sum())\n",
    "print(\"Duplicados:\", df.duplicated().sum())\n",
    "\n",
    "# Tipos de datos\n",
    "print(df.dtypes)"
   ],
   "id": "73be79f37aa0ad75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paso 3.1: Seleccionar Solo Variables Numéricas",
   "id": "c28b75eac7abfc4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Seleccionar solo columnas numéricas\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Matriz de correlación\n",
    "corr = numeric_df.corr()"
   ],
   "id": "21c1d24fecc6beec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paso 3.2: Heatmap de Correlación",
   "id": "4f7756e79f4dcff1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretación\n",
    "\n",
    "Observamos que las variables más correlacionadas con LTV son:\n",
    "\n",
    "- **Total_Spent** (correlación ≈ 1): Esta variable es función directa del LTV en el dataset, por lo cual no debe ser utilizada para predicción (causa fuga de datos).\n",
    "- **Avg_Transaction_Value** y **Total_Transactions** (correlación ≈ 0.66): Estas variables están fuertemente relacionadas con el LTV, pero su combinación reconstruye casi perfectamente el target.\n",
    "- Otras variables como `Max_Transaction_Value`, `Min_Transaction_Value`, y las transformadas WOE de las variables categóricas tienen una correlación baja con LTV (<0.05), indicando que individualmente aportan poca señal para explicar el target.\n",
    "\n",
    "**Conclusión:**\n",
    "Las variables transaccionales (cantidad y valor de transacciones) son los factores más determinantes en el valor de vida del cliente en este dataset. Sin embargo, para un modelo predictivo honesto se deben excluir aquellas que reconstruyen el target."
   ],
   "id": "3e88747a0b3c2104"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de Correlación de Variables Numéricas\")\n",
    "plt.show()"
   ],
   "id": "6efc22e4e5266c9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paso 3.3: Gráfica de Distribución de la Variable Objetivo (LTV)",
   "id": "d1cc0052aa03b885"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['LTV'], bins=50, kde=True)\n",
    "plt.title(\"Distribución de LTV\")\n",
    "plt.xlabel(\"LTV\")\n",
    "plt.show()"
   ],
   "id": "1fb03fffd092b365",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paso 4.1: Crear una variable binaria para regresión logística",
   "id": "481331bd832938e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vamos a transformar LTV en un objetivo binario. Por ejemplo, “1” si el LTV está arriba de la mediana y “0” si está abajo. Esto es común cuando quieres analizar churn, “buenos/malos”, etc.",
   "id": "75bb2641491a8cf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creamos una columna binaria para clasificación (LTV alto/bajo según la mediana)\n",
    "df['LTV_binary'] = (df['LTV'] > df['LTV'].median()).astype(int)"
   ],
   "id": "7bb7b76e29a2c381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paso 4.2: Funciones para calcular WOE e IV",
   "id": "bcda05bd7fa6aad8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "woe_iv() recorre cada categoría de una variable, calcula su Weight of Evidence (WoE) y suma los Information Value (IV).\n",
    "\t•\tWoE indica si la categoría concentra más casos “buenos” (LTV bajo) o “malos” (LTV alto).\n",
    "\t•\tIV total mide el poder predictivo de la variable:\n",
    "\t•\t< 0.02 → irrelevante,\n",
    "\t•\t0.02–0.1 → débil,\n",
    "\t•\t0.1–0.3 → medio,\n",
    "\t•\t> 0.3 → fuerte."
   ],
   "id": "4f042e5d93e0a532"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def woe_iv(df, feature, target):\n",
    "    lst = []\n",
    "    categories = df[feature].unique()\n",
    "    for cat in categories:\n",
    "        good = ((df[feature] == cat) & (df[target] == 0)).sum()\n",
    "        bad = ((df[feature] == cat) & (df[target] == 1)).sum()\n",
    "        dist_good = good / (df[target] == 0).sum()\n",
    "        dist_bad = bad / (df[target] == 1).sum()\n",
    "        # Manejar división por cero y log(0)\n",
    "        if dist_good == 0 or dist_bad == 0:\n",
    "            woe = 0\n",
    "        else:\n",
    "            woe = np.log(dist_bad / dist_good)\n",
    "        iv = (dist_bad - dist_good) * woe\n",
    "        lst.append({'category': cat, 'woe': woe, 'iv': iv})\n",
    "    iv_df = pd.DataFrame(lst)\n",
    "    iv_total = iv_df['iv'].sum()\n",
    "    return iv_df, iv_total"
   ],
   "id": "7ee80ed90a2d63e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paso 4.3: Calcular IV de las variables categóricas",
   "id": "9a7fe577882121e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Declara la lista categorical_vars con las variables categóricas que queremos evaluar.\n",
    "\t•\tRecorre cada columna (for col in categorical_vars:) y llama a woe_iv(df, col, 'LTV_binary'), que devuelve:\n",
    "\t1.\tiv_df → tabla con el WoE y el IV de cada categoría.\n",
    "\t2.\tiv → IV total de toda la variable.\n",
    "\t•\tImprime el IV total de la variable y la tabla detallada (iv_df).\n",
    "\t•\tEl separador print(\"-\"*30) solo pone una línea de guiones para que la salida sea más legible."
   ],
   "id": "c79b891bb04a72f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical_vars = ['Location', 'Income_Level', 'App_Usage_Frequency', 'Preferred_Payment_Method']\n",
    "\n",
    "for col in categorical_vars:\n",
    "    iv_df, iv = woe_iv(df, col, 'LTV_binary')\n",
    "    print(f\"IV for {col}: {iv:.4f}\")\n",
    "    print(iv_df)\n",
    "    print(\"-\"*30)"
   ],
   "id": "f23d1f615f25a76d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paso 4.4: Reemplazar variables categóricas por sus valores WOE (para modelado)",
   "id": "91395936ca75d9cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reemplazar cada categoría por su valor WOE\n",
    "for col in categorical_vars:\n",
    "    iv_df, _ = woe_iv(df, col, 'LTV_binary')\n",
    "    woe_map = dict(zip(iv_df['category'], iv_df['woe']))\n",
    "    df[col + '_WOE'] = df[col].map(woe_map)"
   ],
   "id": "463d687ed200e8e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Variables numéricas (menos LTV y Customer_ID)\n",
    "num_vars = [col for col in numeric_df.columns if col not in ['LTV', 'Customer_ID']]\n",
    "\n",
    "# Variables WOE creadas a partir de las categóricas\n",
    "woe_vars = [col + '_WOE' for col in categorical_vars]"
   ],
   "id": "934a8c4e6a5649bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verifica la correlación de todas las numéricas y WOE con LTV\n",
    "all_vars = num_vars + woe_vars\n",
    "corrs = df[all_vars + ['LTV']].corr()['LTV'].drop('LTV')\n",
    "print(\"Correlación de features con LTV:\")\n",
    "print(corrs.sort_values(ascending=False))\n",
    "\n",
    "# Si alguna variable tiene correlación >0.98 o <-0.98, bórrala del modelado (esto indica fuga de datos)\n",
    "vars_to_drop = corrs[abs(corrs) > 0.98].index.tolist()\n",
    "print(f\"Variables con alta correlación que serán eliminadas del modelo: {vars_to_drop}\")\n",
    "\n",
    "# Redefine X_multiple sin las variables fugadas\n",
    "X_multiple = df[[col for col in (num_vars + woe_vars) if col not in vars_to_drop]]"
   ],
   "id": "23c2fc71d09bc0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chequea si algún subconjunto de columnas puede predecir LTV exactamente (fuga combinada)\n",
    "df['suma_transacciones'] = df['Avg_Transaction_Value'] * df['Total_Transactions']\n",
    "diff = (df['suma_transacciones'] - df['LTV']).abs().sum()\n",
    "print(\"Diferencia total entre suma_transacciones y LTV:\", diff)\n",
    "\n",
    "# También verifica el máximo de diferencia\n",
    "print(\"Máxima diferencia fila a fila:\", (df['suma_transacciones'] - df['LTV']).abs().max())"
   ],
   "id": "185c4c3857045d6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Elimina las variables que reconstruyen LTV casi perfectamente\n",
    "vars_to_remove = ['Total_Transactions', 'Total_Spent','Avg_Transaction_Value']  # Total_Spent ya está fuera, agrega las otras dos\n",
    "\n",
    "# Actualiza num_vars quitando esas columnas\n",
    "num_vars = [col for col in num_vars if col not in vars_to_remove]\n",
    "\n",
    "# Redefine X_multiple y X_logistic con las nuevas variables\n",
    "X_multiple = df[num_vars + woe_vars]\n",
    "X_logistic = df[num_vars + woe_vars]"
   ],
   "id": "fcfe54a2ab86b546",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Construcción de X y y, y división en train/test",
   "id": "e576cd536b7ad48a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Construcción de las matrices X e y\n",
    "\n",
    "Este bloque construye las matrices de entrada (`X`) y salida (`y`) para los tres modelos del proyecto:\n",
    "\n",
    "- Se eliminan variables que causarían fuga de datos (`LTV`, `Total_Spent`, etc.).\n",
    "- Se definen las variables numéricas útiles y las variables categóricas transformadas con WoE.\n",
    "- Se crean tres conjuntos de datos:\n",
    "  - `X_simple` y `y` para regresión lineal simple.\n",
    "  - `X_multiple` y `y` para regresión lineal múltiple.\n",
    "  - `X_logistic` y `y_logistic` para regresión logística.\n",
    "- Finalmente, se realiza la división `train/test` para cada caso con un 70% de datos para entrenamiento y 30% para prueba."
   ],
   "id": "6c1c990cb3586176"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Variables numéricas (menos LTV, Customer_ID, y variables que causan fuga)\n",
    "vars_to_remove = ['LTV', 'Customer_ID', 'Avg_Transaction_Value', 'Total_Transactions', 'Total_Spent', 'suma_transacciones']  # suma_transacciones si la creaste\n",
    "\n",
    "num_vars = [col for col in numeric_df.columns if col not in vars_to_remove]\n",
    "\n",
    "# Agregamos las variables WOE\n",
    "woe_vars = [col + '_WOE' for col in categorical_vars]\n",
    "\n",
    "# X para regresión lineal simple (usando una sola variable, ejemplo Age)\n",
    "X_simple = df[['Age']]\n",
    "y = df['LTV']\n",
    "\n",
    "# X para regresión múltiple (numéricas + WOE)\n",
    "X_multiple = df[num_vars + woe_vars]\n",
    "y = df['LTV']\n",
    "\n",
    "# X para regresión logística (numéricas + WOE)\n",
    "X_logistic = df[num_vars + woe_vars]\n",
    "y_logistic = df['LTV_binary']\n",
    "\n",
    "# División train/test\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_simple, y, test_size=0.3, random_state=42)\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_multiple, y, test_size=0.3, random_state=42)\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_logistic, y_logistic, test_size=0.3, random_state=42)"
   ],
   "id": "f31b01c565c42607",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dimensiones del Dataset",
   "id": "7fe43545e0fe7c4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")",
   "id": "544f6372af22840",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ejemplo de las Primeras Filas",
   "id": "c9034e66187edff1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(df.head())",
   "id": "cab6613477d810f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Distribución de la Variable Objetivo LTV",
   "id": "2afbf44301f151cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['LTV'], bins=50, kde=True)\n",
    "plt.title(\"Distribución de LTV (Variable continua)\")\n",
    "plt.xlabel(\"LTV\")\n",
    "plt.show()"
   ],
   "id": "47b618dce81b8118",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Distribución del Target Binario (LTV_binary)",
   "id": "a26069bd99df1f5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(x='LTV_binary', data=df)\n",
    "plt.title('Distribución LTV_binario (0 = Bajo, 1 = Alto)')\n",
    "plt.xlabel('LTV_binary')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()"
   ],
   "id": "c8f23dffc3f93928",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Boxplot de las variables numéricas más importantes vs LTV_binary",
   "id": "fedf2d0613c02e4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_plot_vars = ['Age', 'Total_Transactions', 'Avg_Transaction_Value', 'Total_Spent']\n",
    "for col in num_plot_vars:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.boxplot(x='LTV_binary', y=col, data=df)\n",
    "    plt.title(f'{col} vs LTV_binary')\n",
    "    plt.show()"
   ],
   "id": "e52b92a12ad1b50c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ejemplo de DataFrame Final",
   "id": "e4c8a893b9c7b92f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(df[[*num_plot_vars, *woe_vars, 'LTV', 'LTV_binary']].head())",
   "id": "43d5e9814817f7a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Eliminación de Outliers\n",
   "id": "e14bfe2e5c7519e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Eliminación de Outliers\n",
    "\n",
    "Este bloque elimina los valores atípicos (outliers) en las variables numéricas. Para cada columna numérica (`num_vars`), se calculan la media y la desviación estándar, y se filtran los valores que estén fuera del rango de 3 desviaciones estándar (\\( \\mu \\pm 3\\sigma \\)). Esto ayuda a reducir el impacto de datos extremos que podrían sesgar los modelos.\n",
    "\n",
    "Luego, se redefine el conjunto de datos (`df_no_outliers`) y se reconstruyen las matrices de entrada (`X`) y salida (`y`) a partir de este nuevo DataFrame filtrado. Se preparan nuevamente los conjuntos para:\n",
    "\n",
    "- `X_simple` y `y`: regresión lineal simple (solo con la variable `Age`).\n",
    "- `X_multiple` y `y`: regresión lineal múltiple (variables numéricas + WoE).\n",
    "- `X_logistic` y `y_logistic`: regresión logística (variables numéricas + WoE).\n",
    "\n",
    "Finalmente, se realiza la división `train/test` para cada conjunto, usando un 70% de los datos para entrenamiento y 30% para prueba."
   ],
   "id": "b185fe05bcadb51e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Opcional: Solo sobre variables numéricas, quita outliers fuera de 3 desviaciones estándar\n",
    "df_no_outliers = df.copy()\n",
    "for col in num_vars:\n",
    "    m = df_no_outliers[col].mean()\n",
    "    s = df_no_outliers[col].std()\n",
    "    df_no_outliers = df_no_outliers[(df_no_outliers[col] > m - 3*s) & (df_no_outliers[col] < m + 3*s)]\n",
    "\n",
    "print(f\"Filas después de eliminar outliers: {df_no_outliers.shape[0]}\")\n",
    "\n",
    "# Redefine tus X y y a partir de df_no_outliers, no de df\n",
    "X_simple = df_no_outliers[['Age']]\n",
    "y = df_no_outliers['LTV']\n",
    "X_multiple = df_no_outliers[num_vars + woe_vars]\n",
    "X_logistic = df_no_outliers[num_vars + woe_vars]\n",
    "y_logistic = df_no_outliers['LTV_binary']\n",
    "\n",
    "# Split como antes\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_simple, y, test_size=0.3, random_state=42)\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_multiple, y, test_size=0.3, random_state=42)\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_logistic, y_logistic, test_size=0.3, random_state=42)"
   ],
   "id": "84d0f708ef02cab0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Regresión Lineal Simple",
   "id": "7d4c4ed376126cbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Regresión Lineal Simple\n",
    "\n",
    "En este bloque se entrena un modelo de **regresión lineal simple** utilizando únicamente la variable `Age` para predecir el LTV.\n",
    "\n",
    "- Se entrena el modelo con `X_train_s` y `y_train_s`.\n",
    "- Se generan predicciones sobre el conjunto de prueba (`X_test_s`).\n",
    "- Se calculan dos métricas:\n",
    "  - **RMSE**: error cuadrático medio.\n",
    "  - **R² (coeficiente de determinación)**: proporción de varianza explicada por el modelo.\n",
    "\n",
    "#### Resultados:\n",
    "\n",
    "- **RMSE:** 429404.57\n",
    "- **R²:** -0.0029\n",
    "\n",
    "#### Interpretación:\n",
    "\n",
    "El modelo tiene un desempeño muy pobre:\n",
    "- El R² negativo indica que el modelo **predice peor que una media constante**.\n",
    "- `Age` por sí sola **no explica el LTV** de los clientes.\n",
    "- El gráfico muestra que los puntos están lejos de la línea de referencia (roja), lo cual confirma el bajo poder predictivo del modelo."
   ],
   "id": "c9c21e2e23cd34c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Modelo de regresión lineal simple\n",
    "lr_simple = LinearRegression()\n",
    "lr_simple.fit(X_train_s, y_train_s)\n",
    "y_pred_simple = lr_simple.predict(X_test_s)\n",
    "\n",
    "# Métricas\n",
    "rmse_simple = np.sqrt(mean_squared_error(y_test_s, y_pred_simple))\n",
    "r2_simple = r2_score(y_test_s, y_pred_simple)\n",
    "\n",
    "print(\"Regresión Lineal Simple (usando 'Age'):\")\n",
    "print(f\"RMSE: {rmse_simple:.2f}\")\n",
    "print(f\"R^2: {r2_simple:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_test_s, y_pred_simple, alpha=0.5)\n",
    "plt.xlabel(\"LTV Real\")\n",
    "plt.ylabel(\"LTV Predicho\")\n",
    "plt.title(\"Regresión Lineal Simple - Age\")\n",
    "plt.plot([y_test_s.min(), y_test_s.max()], [y_test_s.min(), y_test_s.max()], 'r--')\n",
    "plt.show()"
   ],
   "id": "b5d67a01b2e42a7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Regresión Lineal Múltiple",
   "id": "9bfffa78f44dbe79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Regresión Lineal Múltiple\n",
    "\n",
    "En este bloque se entrena un modelo de **regresión lineal múltiple** utilizando todas las variables numéricas (excepto las que causan fuga de datos) y las variables categóricas transformadas con WoE.\n",
    "\n",
    "- El modelo se entrena con `X_train_m` y `y_train_m`.\n",
    "- Se evalúa sobre `X_test_m` y se calculan las métricas:\n",
    "  - **RMSE**: error cuadrático medio.\n",
    "  - **R² (coeficiente de determinación)**: proporción de varianza explicada por el modelo.\n",
    "- También se genera un gráfico de dispersión entre el LTV real y el LTV predicho.\n",
    "\n",
    "#### Resultados:\n",
    "\n",
    "- **RMSE:** 347832.57\n",
    "- **R²:** 0.3419\n",
    "\n",
    "#### Interpretación:\n",
    "\n",
    "- El modelo logra explicar aproximadamente el **34% de la varianza** del LTV.\n",
    "- Aunque no es excelente, este resultado es **aceptable en contextos reales** donde las variables disponibles no explican completamente el comportamiento del cliente.\n",
    "- El gráfico muestra una tendencia ascendente, aunque con bastante dispersión, lo que sugiere que el modelo tiene **capacidad moderada para predecir** el LTV."
   ],
   "id": "6853b27072cc0bba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Modelo de regresión lineal múltiple\n",
    "lr_multiple = LinearRegression()\n",
    "lr_multiple.fit(X_train_m, y_train_m)\n",
    "y_pred_multiple = lr_multiple.predict(X_test_m)\n",
    "\n",
    "# Métricas\n",
    "rmse_multiple = np.sqrt(mean_squared_error(y_test_m, y_pred_multiple))\n",
    "r2_multiple = r2_score(y_test_m, y_pred_multiple)\n",
    "\n",
    "print(\"Regresión Lineal Múltiple:\")\n",
    "print(f\"RMSE: {rmse_multiple:.2f}\")\n",
    "print(f\"R^2: {r2_multiple:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_test_m, y_pred_multiple, alpha=0.5)\n",
    "plt.xlabel(\"LTV Real\")\n",
    "plt.ylabel(\"LTV Predicho\")\n",
    "plt.title(\"Regresión Lineal Múltiple\")\n",
    "plt.plot([y_test_m.min(), y_test_m.max()], [y_test_m.min(), y_test_m.max()], 'r--')\n",
    "plt.show()"
   ],
   "id": "16ea119b679c2774",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Comparar mejoras en regresión múltiple",
   "id": "ba3e74bf8b77f991"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "# 1. Regresión múltiple normal (ya la tienes, solo mostramos resultados otra vez)\n",
    "print(\"Regresión Múltiple (Normal)\")\n",
    "print(f\"RMSE: {rmse_multiple:.2f}\")\n",
    "print(f\"R^2: {r2_multiple:.4f}\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# 2. Regresión múltiple con escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_m_sc = scaler.fit_transform(X_train_m)\n",
    "X_test_m_sc = scaler.transform(X_test_m)\n",
    "\n",
    "lr_scaled = LinearRegression()\n",
    "lr_scaled.fit(X_train_m_sc, y_train_m)\n",
    "y_pred_scaled = lr_scaled.predict(X_test_m_sc)\n",
    "rmse_scaled = np.sqrt(mean_squared_error(y_test_m, y_pred_scaled))\n",
    "r2_scaled = r2_score(y_test_m, y_pred_scaled)\n",
    "print(\"Regresión Múltiple (Estandarizada)\")\n",
    "print(f\"RMSE: {rmse_scaled:.2f}\")\n",
    "print(f\"R^2: {r2_scaled:.4f}\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# 3. Regresión múltiple con interacciones (polinomial de grado 2)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_m_poly = poly.fit_transform(X_train_m)\n",
    "X_test_m_poly = poly.transform(X_test_m)\n",
    "\n",
    "lr_poly = LinearRegression()\n",
    "lr_poly.fit(X_train_m_poly, y_train_m)\n",
    "y_pred_poly = lr_poly.predict(X_test_m_poly)\n",
    "rmse_poly = np.sqrt(mean_squared_error(y_test_m, y_pred_poly))\n",
    "r2_poly = r2_score(y_test_m, y_pred_poly)\n",
    "print(\"Regresión Múltiple (Interacciones)\")\n",
    "print(f\"RMSE: {rmse_poly:.2f}\")\n",
    "print(f\"R^2: {r2_poly:.4f}\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# 4. Regresión múltiple con logaritmo del target\n",
    "# Solo si LTV no tiene valores negativos o cero\n",
    "if (y_train_m > 0).all() and (y_test_m > 0).all():\n",
    "    y_train_log = np.log1p(y_train_m)\n",
    "    y_test_log = np.log1p(y_test_m)\n",
    "    lr_log = LinearRegression()\n",
    "    lr_log.fit(X_train_m, y_train_log)\n",
    "    y_pred_log = lr_log.predict(X_test_m)\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_log))\n",
    "    r2_log = r2_score(y_test_log, y_pred_log)\n",
    "    print(\"Regresión Múltiple (Log-LTV)\")\n",
    "    print(f\"RMSE: {rmse_log:.2f}\")\n",
    "    print(f\"R^2: {r2_log:.4f}\")\n",
    "    print(\"-\"*30)\n",
    "else:\n",
    "    print(\"LTV tiene valores <= 0, no se puede aplicar logaritmo.\")"
   ],
   "id": "c5c1aa461f27cabe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparación de Regresiones Lineales Múltiples con Distintas Transformaciones\n",
    "\n",
    "Se evaluaron distintas variantes de regresión lineal múltiple para observar si alguna mejora el rendimiento predictivo sobre el LTV:\n",
    "\n",
    "1. **Regresión Múltiple Normal**\n",
    "   - Modelo base sin transformación adicional.\n",
    "   - **RMSE:** 347,832.57\n",
    "   - **R²:** 0.3419\n",
    "\n",
    "2. **Regresión Múltiple Estandarizada**\n",
    "   - Se estandarizan todas las variables con `StandardScaler`.\n",
    "   - El resultado es **idéntico** al modelo normal porque no se aplicó regularización, por lo tanto **la escala no afecta el modelo**.\n",
    "   - **RMSE:** 347,832.57\n",
    "   - **R²:** 0.3419\n",
    "\n",
    "3. **Regresión con Interacciones**\n",
    "   - Se agregan términos de interacción entre pares de variables (productos cruzados).\n",
    "   - Hubo **una leve mejora** en el rendimiento.\n",
    "   - **RMSE:** 346,758.06\n",
    "   - **R²:** 0.3460\n",
    "\n",
    "4. **Regresión con Logaritmo del Target (Log-LTV)**\n",
    "   - Se aplicó una transformación logarítmica a la variable objetivo `LTV` para reducir su escala y sesgo.\n",
    "   - La métrica RMSE no es comparable directamente (está en escala log).\n",
    "   - **RMSE:** 0.97 (log-scale)\n",
    "   - **R²:** 0.3321\n",
    "\n",
    "---\n",
    "\n",
    "#### Conclusión:\n",
    "\n",
    "- **Estandarizar** no tiene impacto si no se usa regularización.\n",
    "- **Agregar interacciones** tiene un pequeño efecto positivo.\n",
    "- **Transformar el target** con logaritmo no mejora sustancialmente el modelo.\n",
    "\n",
    "Estas pruebas refuerzan que el dataset no tiene variables con suficiente capacidad explicativa del LTV, por lo que incluso con ingeniería de variables avanzada, las mejoras son marginales."
   ],
   "id": "84e224fc822160cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Regresion logistica",
   "id": "fb661516d85603c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Escala tus variables",
   "id": "ae757bdcdd373285"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Regresión Logística con Escalado\n",
    "\n",
    "Este bloque implementa un modelo de **regresión logística** para predecir si un cliente tiene un LTV alto o bajo (`LTV_binary`), utilizando variables numéricas y WoE escaladas.\n",
    "\n",
    "#### Pasos clave:\n",
    "\n",
    "- Se aplica `StandardScaler` para **escalar las variables predictoras**, lo cual es recomendable para algoritmos como la regresión logística.\n",
    "- Se entrena el modelo con `X_train_l_sc` y `y_train_l`, usando `LogisticRegression()` con un máximo de 2000 iteraciones para asegurar convergencia.\n",
    "- Se generan predicciones de clase (`y_pred_logr`) y de probabilidad (`y_pred_logr_proba`), esta última necesaria para métricas como ROC AUC y KS.\n",
    "\n",
    "Esta preparación es esencial para evaluar correctamente la capacidad del modelo de clasificar clientes en grupos de alto o bajo valor."
   ],
   "id": "4b59fc51785c9e76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_l_sc = scaler.fit_transform(X_train_l)\n",
    "X_test_l_sc = scaler.transform(X_test_l)\n",
    "\n",
    "logr = LogisticRegression(max_iter=2000)\n",
    "logr.fit(X_train_l_sc, y_train_l)\n",
    "y_pred_logr = logr.predict(X_test_l_sc)\n",
    "y_pred_logr_proba = logr.predict_proba(X_test_l_sc)[:, 1]"
   ],
   "id": "ed6cb6c00bef8046",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# REGRESIÓN LOGÍSTICA: Predicción de LTV alto (1) vs bajo (0)\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "\n",
    "# Entrenar modelo\n",
    "logr = LogisticRegression(max_iter=3000)\n",
    "logr.fit(X_train_l, y_train_l)\n",
    "y_pred_logr = logr.predict(X_test_l)\n",
    "y_pred_logr_proba = logr.predict_proba(X_test_l)[:, 1]\n",
    "\n",
    "# Métricas\n",
    "acc_logr = accuracy_score(y_test_l, y_pred_logr)\n",
    "roc_auc = roc_auc_score(y_test_l, y_pred_logr_proba)\n",
    "\n",
    "print(\"Regresión Logística (predice LTV alto vs bajo)\")\n",
    "print(f\"Accuracy: {acc_logr:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# KS Statistic (Kolmogorov-Smirnov)\n",
    "ks = ks_2samp(y_pred_logr_proba[y_test_l==1], y_pred_logr_proba[y_test_l==0]).statistic\n",
    "print(f\"KS Statistic: {ks:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_mat = confusion_matrix(y_test_l, y_pred_logr)\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matriz de Confusión - Regresión Logística\")\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_l, y_pred_logr_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC - Regresión Logística')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "ae66d5b9bdec8440",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Regresión Logística: Predicción de LTV Alto vs Bajo\n",
    "\n",
    "Este bloque implementa un modelo de **regresión logística** para clasificar a los clientes según si tienen un **LTV alto (1)** o **bajo (0)**. Se evaluó su rendimiento con métricas estándar de clasificación.\n",
    "\n",
    "#### Resultados:\n",
    "- **Accuracy:** 0.7188\n",
    "- **ROC AUC:** 0.8013\n",
    "- **KS Statistic:** 0.5013\n",
    "\n",
    "#### Interpretación:\n",
    "- El **accuracy** de ~71.88% indica una buena capacidad de clasificación general.\n",
    "- El **área bajo la curva ROC (0.80)** sugiere que el modelo discrimina bien entre clases, es decir, logra separar a los clientes de alto y bajo valor con bastante efectividad.\n",
    "- El **KS (Kolmogorov-Smirnov) de 0.50** refuerza esta capacidad discriminativa, y es un valor considerado muy bueno en modelos de scoring.\n",
    "- La **matriz de confusión** muestra el desempeño por clase, evidenciando que hay una cantidad equilibrada de verdaderos positivos y negativos.\n",
    "- La **curva ROC** representa gráficamente la capacidad del modelo para distinguir entre clases, mostrando una mejora clara respecto a un clasificador aleatorio (línea diagonal).\n",
    "\n",
    "**Conclusión:**\n",
    "La regresión logística resulta ser el modelo más efectivo cuando el objetivo es **clasificar clientes entre alto y bajo LTV**, superando tanto al modelo lineal simple como al múltiple en métricas clave."
   ],
   "id": "e2c5658d32bea8e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Bloque comparativo",
   "id": "83bc38e2582c6ebd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# --- Regresión lineal simple ---\n",
    "# Ya tienes: y_test_s, y_pred_simple, rmse_simple, r2_simple\n",
    "\n",
    "# Para KS en lineales, binarizamos la predicción usando la mediana del LTV para comparar\n",
    "y_pred_simple_binary = (y_pred_simple > np.median(y_test_s)).astype(int)\n",
    "y_test_s_binary = (y_test_s > np.median(y_test_s)).astype(int)\n",
    "ks_simple = ks_2samp(y_pred_simple_binary[y_test_s_binary == 1], y_pred_simple_binary[y_test_s_binary == 0]).statistic\n",
    "\n",
    "# --- Regresión lineal múltiple ---\n",
    "# Ya tienes: y_test_m, y_pred_multiple, rmse_multiple, r2_multiple\n",
    "y_pred_multiple_binary = (y_pred_multiple > np.median(y_test_m)).astype(int)\n",
    "y_test_m_binary = (y_test_m > np.median(y_test_m)).astype(int)\n",
    "ks_multiple = ks_2samp(y_pred_multiple_binary[y_test_m_binary == 1], y_pred_multiple_binary[y_test_m_binary == 0]).statistic\n",
    "\n",
    "# --- Regresión logística ---\n",
    "# Ya tienes: y_test_l, y_pred_logr_proba, acc_logr, roc_auc, ks (ya calculado)\n",
    "# Como RMSE de probabilidades vs clase real (no es tan interpretado, pero sirve para comparar)\n",
    "rmse_logr = np.sqrt(mean_squared_error(y_test_l, y_pred_logr_proba))\n",
    "\n",
    "# --- Tabla comparativa ---\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Modelo':<25}{'RMSE':<12}{'R^2':<12}{'KS':<12}\")\n",
    "print(\"-\"*40)\n",
    "print(f\"{'Lineal Simple':<25}{rmse_simple:<12.2f}{r2_simple:<12.4f}{ks_simple:<12.4f}\")\n",
    "print(f\"{'Lineal Múltiple':<25}{rmse_multiple:<12.2f}{r2_multiple:<12.4f}{ks_multiple:<12.4f}\")\n",
    "print(f\"{'Logística':<25}{rmse_logr:<12.4f}{'N/A':<12}{ks:<12.4f}\")\n",
    "print(\"=\"*40)"
   ],
   "id": "3a8f715fd22370b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparación de Modelos Predictivos: Lineal Simple, Lineal Múltiple y Logístico\n",
    "\n",
    "En este bloque se comparan los tres enfoques de modelado utilizados en el proyecto: **regresión lineal simple**, **regresión lineal múltiple**, y **regresión logística**. Para hacer la comparación más justa, se calculan tres métricas para cada modelo:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** mide el error promedio de las predicciones. En regresión logística se calcula usando la probabilidad estimada vs. clase real (no es la métrica ideal, pero es útil como referencia).\n",
    "- **R² (Coeficiente de Determinación):** indica cuánta varianza del target es explicada por el modelo. No aplica para regresión logística.\n",
    "- **KS (Kolmogorov-Smirnov):** mide la capacidad de un modelo para separar correctamente entre clases altas y bajas de LTV. Se binariza el target en los modelos lineales para poder compararlo.\n",
    "\n",
    "#### Resultados\n",
    "\n",
    "| Modelo          | RMSE        | R²       | KS     |\n",
    "|-----------------|-------------|----------|--------|\n",
    "| Lineal Simple   | 429404.57   | -0.0029  | 0.0000 |\n",
    "| Lineal Múltiple | 347832.57   | 0.3419   | 0.5071 |\n",
    "| Logística       | 0.4305      | N/A      | 0.5013 |\n",
    "\n",
    "#### Interpretación\n",
    "\n",
    "- **Lineal Simple:** Tiene el peor desempeño. El R² negativo y un KS de 0 indican que usar una sola variable (como la edad) no tiene poder predictivo.\n",
    "- **Lineal Múltiple:** Mejora notablemente el RMSE y alcanza un R² razonable de 0.34. Además, logra discriminar bastante bien entre clientes de alto y bajo LTV (KS = 0.51).\n",
    "- **Logística:** Aunque su RMSE no es comparable directamente, el **KS de 0.50** y el **ROC AUC de ~0.80** (visto anteriormente) demuestran que es el modelo más adecuado si el objetivo es **clasificación binaria** (alto vs bajo LTV).\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusión:**\n",
    "La regresión logística es el mejor modelo para **clasificación de clientes**, mientras que la regresión lineal múltiple es útil si el objetivo es **predecir un valor numérico** del LTV."
   ],
   "id": "edd8d4c9ed50826c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "# Guarda el modelo y el scaler (si usaste StandardScaler)\n",
    "joblib.dump(logr, 'modelo_logistico.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')  # si usaste uno"
   ],
   "id": "224645774affb193",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
